# Face & Voice Recognition System ğŸ­

A modern web-based face and voice recognition system using advanced CNN (Convolutional Neural Networks) with enhanced feature extraction and multiple model architectures for improved accuracy.

## ğŸ‰ Latest UI/UX Updates & Key Features

### âœ¨ Modern Interface Overhaul
- **Glassmorphism Design**: Beautiful glass-like UI with blur effects and transparency
- **Responsive Layout**: Works seamlessly on desktop, tablet, and mobile devices
- **Smooth Animations**: Fade-in, slide-up, pulse, and hover effects throughout the interface
- **Interactive Components**: Real-time feedback, progress indicators, and visual state changes

### ğŸš€ Enhanced User Experience
- **Dedicated Pages**: Specialized interfaces for each function (training, recognition, settings)
- **Live Camera Integration**: Real-time camera feed with automatic face detection overlay
- **Audio Visualization**: Dynamic microphone indicators and waveform displays
- **Drag & Drop Support**: Modern file upload with preview capabilities
- **Progress Tracking**: Animated progress bars and status indicators for all operations

### ğŸ¨ Professional Design Elements
- **Modern Typography**: Inter font family for clean, professional appearance
- **Gradient Backgrounds**: Beautiful color gradients and dynamic visual elements
- **Card-Based Layout**: Organized content in modern cards with shadow effects
- **Interactive Buttons**: Hover effects and smooth transitions for better user engagement

## Features âœ¨

- **Advanced Face Recognition**: CNN-based facial recognition using computer vision with real-time camera integration
- **Enhanced Voice Recognition**: Multi-feature extraction (MFCC, Chroma, Spectral Contrast) with CNN and live recording
- **Multiple Model Architectures**: Standard, focused, balanced, and ensemble models for optimal accuracy
- **Dual-Model System**: Intelligent model switching and consensus for better accuracy
- **Modern Web UI**: Glassmorphism design with responsive layout and smooth animations
- **Real-time Processing**: Live camera feed and microphone input with visual feedback
- **Interactive Components**: Drag-and-drop file uploads, progress indicators, and status animations
- **Dedicated Pages**: Specialized interfaces for training, recognition, and system settings
- **Robust Feature Extraction**: Enhanced audio processing with fallback support
- **Model Training**: Train multiple custom models with your own data through intuitive interfaces
- **Multi-format Support**: Images (JPG, PNG) and audio files (WAV, MP3) with preview capabilities
- **Performance Analytics**: Detailed testing and validation tools with visual dashboards

## Technologies Used ğŸ”§

- **Backend**: Python Flask, TensorFlow/Keras, OpenCV with advanced CNN architectures
- **Frontend**: HTML5, CSS3, JavaScript with Glassmorphism design and modern animations
- **UI/UX**: Responsive design, Inter typography, gradient backgrounds, interactive components
- **Machine Learning**: Advanced CNN models with multiple architectures and ensemble methods
- **Audio Processing**: Librosa with enhanced feature extraction (MFCC, Chroma, Spectral Contrast)
- **Computer Vision**: OpenCV for face detection and real-time camera processing
- **Model Optimization**: Ensemble methods, Random Forest, SVM with intelligent model switching
- **Configuration Management**: Centralized config system with performance analytics

## Installation ğŸš€

### Method 1: Automatic Setup
```bash
python setup.py
```

### Method 2: Manual Setup
1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Organize your data:
```
face_data/
â”œâ”€â”€ Person1/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â””â”€â”€ img2.jpg
â””â”€â”€ Person2/
    â”œâ”€â”€ img1.jpg
    â””â”€â”€ img2.jpg

voice_data/
â”œâ”€â”€ Person1/
â”‚   â”œâ”€â”€ sample1.wav
â”‚   â””â”€â”€ sample2.wav
â””â”€â”€ Person2/
    â”œâ”€â”€ sample1.wav
    â””â”€â”€ sample2.wav
```

3. Run the application:
```bash
python app.py
```

4. Open your browser and go to: `http://localhost:5000`

## Usage ğŸ“–

### ğŸ¨ Modern Web Interface
The system features a beautiful, modern interface with:
- **Glassmorphism Design**: Translucent cards with backdrop blur effects
- **Smooth Animations**: Fade-in, slide-up, and hover animations throughout
- **Responsive Layout**: Works perfectly on desktop, tablet, and mobile devices
- **Interactive Elements**: Hover effects, progress indicators, and real-time feedback

### 1. Training Models
- Navigate to dedicated training pages through the main interface
- **Face Training**: Upload images through drag-and-drop or file browser
- **Voice Training**: Record samples directly or upload audio files
- Real-time progress tracking with animated progress bars
- Visual feedback for training completion and model status

### 2. Face Recognition
- **Live Camera**: Modern camera interface with real-time preview
  - Click "Start Camera" for live feed
  - "Capture Photo" with instant preview
  - Automatic face detection overlay
- **File Upload**: Drag-and-drop interface with file preview
- Results display with confidence scores and visual indicators
- Smooth transitions between states (scanning, processing, results)

### 3. Voice Recognition
- **Live Recording**: Interactive microphone interface
  - Visual recording indicators with pulse animations
  - Real-time audio level visualization
  - "Start Recording" â†’ speak â†’ "Stop Recording" workflow
- **File Upload**: Modern file browser with audio preview
- Audio waveform visualization during processing
- Results with confidence scores and alternative predictions

### ğŸ¯ Enhanced User Experience Features
- **Visual Feedback**: Loading spinners, progress bars, and status indicators
- **Error Handling**: User-friendly error messages with recovery suggestions
- **Settings Dashboard**: Comprehensive system configuration interface
- **Analytics View**: Performance metrics and recognition history

## Data Requirements ğŸ“Š

### Face Data
- **Format**: JPG, PNG images
- **Quantity**: At least 5-10 images per person
- **Quality**: Clear, well-lit faces
- **Size**: Any size (automatically resized to 128x128)

### Voice Data
- **Format**: WAV, MP3 audio files
- **Duration**: 2-5 seconds per sample
- **Quantity**: At least 3-5 samples per person
- **Quality**: Clear speech, minimal background noise

## Model Architecture ğŸ§ 

### Face Recognition CNN
```
Conv2D(32) â†’ MaxPool â†’ Conv2D(64) â†’ MaxPool â†’ Conv2D(128) â†’ MaxPool â†’ Dense(128) â†’ Output
```

### Voice Recognition System
The system includes multiple model architectures:

#### Enhanced CNN Models
```
Input: Multi-feature audio (32Ã—130Ã—1 or 32Ã—36Ã—1)
- MFCC features (13): Spectral characteristics
- Chroma features (12): Pitch class profiles  
- Spectral Contrast (7): Timbral texture
Conv2D(32) â†’ MaxPool â†’ Conv2D(64) â†’ MaxPool â†’ Conv2D(128) â†’ MaxPool â†’ Dense(128) â†’ Output
```

#### Specialized Models
- **Standard Model**: General-purpose voice recognition
- **Focused Models**: Person-specific optimization (e.g., Athul-focused)
- **Balanced Model**: Multi-user optimization
- **Ensemble Model**: Random Forest + SVM with statistical features

#### Dual-Model System
- Intelligent model switching based on confidence scores
- Consensus prediction from multiple models
- Enhanced accuracy through model combination

## Recent Improvements ğŸš€

### ğŸ¨ Modern UI/UX Enhancements
- **Glassmorphism Design**: Modern glass-like UI with backdrop blur effects and transparency layers
- **Responsive Layout**: Fully responsive design that adapts to all screen sizes and devices
- **Advanced Animations**: Smooth CSS animations including fade-in, slide-up, pulse, and hover effects
- **Interactive Elements**: Enhanced hover states with transform effects and dynamic color changes
- **Modern Typography**: Inter font family for clean, professional appearance
- **Gradient Backgrounds**: Beautiful gradient overlays and dynamic visual elements
- **Card-Based Layout**: Organized content in modern card components with shadow effects
- **Professional Navigation**: Intuitive navigation with back buttons and smooth transitions

### ğŸ“± Enhanced User Interface Features
- **Dedicated Pages**: Separate specialized pages for each functionality:
  - `face_recognition.html` - Face verification with live camera feed
  - `voice_recognition.html` - Voice verification with real-time audio processing
  - `train_face.html` - Face model training interface
  - `train_voice.html` - Voice model training interface
  - `settings.html` - System configuration and analytics dashboard
  - `results.html` - Recognition results display with confidence scores

### ğŸ¯ Interactive UI Components
- **Live Camera Integration**: Real-time camera feed with capture functionality
- **Audio Visualization**: Dynamic microphone visualization with recording indicators
- **Progress Indicators**: Training progress bars and status animations
- **Drag & Drop Support**: Modern file upload with drag-and-drop functionality
- **Real-time Feedback**: Instant visual feedback for user actions
- **Status Indicators**: Clear visual states for recording, processing, and results

### Voice Recognition Enhancements
- **Multi-Feature Extraction**: Combined MFCC, Chroma, and Spectral Contrast features (32 total vs. 13 previously)
- **Advanced Model Architectures**: Multiple specialized models for different scenarios
- **Dual-Model System**: Intelligent switching between models based on confidence
- **Ensemble Methods**: Random Forest and SVM models for statistical analysis
- **Enhanced Preprocessing**: Improved normalization and feature-type specific processing
- **Robust Error Handling**: Comprehensive fallbacks for different librosa versions

### System Optimizations
- **Configuration Management**: Centralized config system for easy parameter tuning
- **Performance Analytics**: Detailed testing and validation tools
- **Memory Optimization**: Efficient model loading and prediction processes
- **JSON Serialization**: Fixed numpy type conversion issues
- **Sample Rate Consistency**: Standardized audio processing across all models

### Model Performance
- **Focused Models**: Up to 100% accuracy for specific individuals
- **Balanced Models**: Optimized for multi-user scenarios (60% overall accuracy)
- **Consensus Prediction**: Combines multiple model outputs for better reliability

## API Endpoints ğŸ”Œ

- `GET /` - Main web interface with modern dashboard
- `POST /train` - Train models with current data
- `POST /recognize_face` - Recognize face from image
- `POST /recognize_voice` - Recognize voice from audio
- `GET /face-recognition` - Face verification interface
- `GET /voice-recognition` - Voice verification interface
- `GET /train-face` - Face model training interface
- `GET /train-voice` - Voice model training interface
- `GET /settings` - System configuration dashboard

## ğŸ¨ UI/UX Design Philosophy

### Modern Glassmorphism Aesthetic
Our interface embraces the latest design trends with:
- **Glass-like transparency effects** using CSS `backdrop-filter: blur()`
- **Layered depth** with shadows and gradient overlays
- **Smooth micro-interactions** that respond to user input
- **Professional color palette** with carefully chosen gradients

### User-Centric Design Principles
- **Intuitive Navigation**: Clear visual hierarchy and logical flow
- **Immediate Feedback**: Real-time visual responses to user actions
- **Accessibility**: High contrast ratios and readable typography
- **Progressive Enhancement**: Graceful degradation across devices

### Interactive Components
- **Animated State Changes**: Smooth transitions between UI states
- **Hover Effects**: Subtle animations that guide user attention
- **Loading States**: Engaging progress indicators and spinners
- **Error Recovery**: Clear messaging with actionable solutions

### Responsive Architecture
- **Mobile-First Design**: Optimized for touch interactions
- **Flexible Grid System**: Adapts to any screen size seamlessly
- **Touch-Friendly Controls**: Appropriately sized interactive elements
- **Performance Optimized**: Lightweight CSS with hardware acceleration

## Performance Tips ğŸ’¡

1. **Face Recognition**:
   - Use well-lit, clear images with the enhanced camera interface
   - Include various angles and expressions through the training interface
   - Ensure faces are clearly visible with automatic detection feedback
   - Utilize the real-time camera preview for optimal positioning

2. **Voice Recognition**:
   - Record in quiet environments using the visual audio level indicators
   - Use consistent microphone/recording setup with the built-in recorder
   - Include various speaking styles through the enhanced training interface
   - Ensure 2-5 second audio samples for best results with waveform preview

3. **Model Training**:
   - More data generally improves accuracy - track progress with visual indicators
   - Balance the number of samples per person using the analytics dashboard
   - Use multiple model types for different scenarios through the settings panel
   - Retrain models when adding new people with guided workflows
   - Consider person-specific focused models for difficult cases

4. **System Optimization**:
   - The dual-model system automatically selects the best approach
   - Ensemble methods provide fallback for edge cases
   - Enhanced feature extraction improves discrimination
   - Monitor performance through the settings dashboard

5. **UI/UX Optimization**:
   - Use drag-and-drop functionality for faster file uploads
   - Monitor real-time feedback during training and recognition
   - Access quick settings through the modern interface
   - Utilize keyboard shortcuts and touch gestures where available

## Troubleshooting ğŸ”§

### Common Issues

1. **Camera not working**:
   - Check browser permissions
   - Ensure no other applications are using the camera

2. **Microphone not working**:
   - Check browser permissions
   - Verify microphone is properly connected

3. **Poor recognition accuracy**:
   - Add more training samples
   - Ensure good quality data
   - Retrain the models

4. **Installation issues**:
   - Update pip: `python -m pip install --upgrade pip`
   - Use virtual environment
   - Check Python version (3.8+ required)

## File Structure ğŸ“

```
Face Recognition/
â”œâ”€â”€ app.py                          # Main Flask application with dual-model system
â”œâ”€â”€ setup.py                       # Setup script
â”œâ”€â”€ config.py                      # Configuration management
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ .gitignore                     # Git ignore rules
â”œâ”€â”€ templates/                     # Modern UI Templates
â”‚   â”œâ”€â”€ index.html                 # Main dashboard with glassmorphism design
â”‚   â”œâ”€â”€ face_recognition.html      # Face verification interface
â”‚   â”œâ”€â”€ voice_recognition.html     # Voice verification interface
â”‚   â”œâ”€â”€ train_face.html           # Face model training interface
â”‚   â”œâ”€â”€ train_voice.html          # Voice model training interface
â”‚   â”œâ”€â”€ settings.html             # System configuration dashboard
â”‚   â”œâ”€â”€ results.html              # Recognition results display
â”‚   â””â”€â”€ home.html                 # Alternative home interface
â”œâ”€â”€ face_data/                     # Face training images
â”œâ”€â”€ voice_data/                    # Voice training samples
â”œâ”€â”€ Models & Encoders/             # Trained Models
â”‚   â”œâ”€â”€ face_model.h5             # Trained face model
â”‚   â”œâ”€â”€ face_encoder.pkl          # Face label encoder
â”‚   â”œâ”€â”€ voice_model.h5            # Standard voice model
â”‚   â”œâ”€â”€ voice_encoder.pkl         # Voice label encoder
â”‚   â”œâ”€â”€ balanced_voice_model.h5   # Balanced voice model
â”‚   â”œâ”€â”€ balanced_voice_encoder.pkl # Balanced model encoder
â”‚   â”œâ”€â”€ focused_voice_model.h5    # Person-focused models
â”‚   â”œâ”€â”€ voice_ensemble_models.pkl # Ensemble models
â”‚   â””â”€â”€ voice_features.pkl        # Processed voice features
â”œâ”€â”€ Analysis & Testing Scripts/    # Development Tools
â”‚   â”œâ”€â”€ test_system.py            # System validation
â”‚   â”œâ”€â”€ validate_system.py        # Model testing
â”‚   â”œâ”€â”€ analyze_all_voices.py     # Voice analysis tools
â”‚   â”œâ”€â”€ compare_all_models.py     # Model comparison
â”‚   â”œâ”€â”€ improve_all_voices.py     # Voice improvement scripts
â”‚   â”œâ”€â”€ fix_voice_confusion.py    # Confusion resolution
â”‚   â””â”€â”€ final_voice_optimization.py # Ensemble optimization
â”œâ”€â”€ Documentation/                 # Project Documentation
â”‚   â”œâ”€â”€ FINAL_PROJECT_STATUS.md   # Project status report
â”‚   â”œâ”€â”€ IMPROVEMENTS_SUMMARY.md   # Improvement documentation
â”‚   â””â”€â”€ USAGE_SUMMARY.md         # Usage guidelines
â””â”€â”€ Output Logs/                  # Analysis Results
    â”œâ”€â”€ voice_test_output.txt     # Test results
    â”œâ”€â”€ analysis_output.txt       # Analysis logs
    â””â”€â”€ improvement_output.txt    # Improvement logs
```

## Security Notes ğŸ”’

- Models and data are stored locally
- No data is transmitted to external servers
- Camera and microphone access requires user permission
- Consider implementing authentication for production use

## Contributing ğŸ¤

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License ğŸ“„

This project is open source and available under the MIT License.

## Credits ğŸ‘

- TensorFlow/Keras for deep learning framework
- OpenCV for computer vision operations
- Librosa for audio processing
- Flask for web framework
