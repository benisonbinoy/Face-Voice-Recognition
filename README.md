# Face & Voice Recognition System ğŸ­

A modern web-based face and voice recognition system using CNN (Convolutional Neural Networks) with a beautiful, responsive UI.

## Features âœ¨

- **Face Recognition**: CNN-based facial recognition using computer vision
- **Voice Recognition**: MFCC feature extraction with CNN for voice identification
- **Real-time Processing**: Live camera feed and microphone input
- **Modern Web UI**: Responsive design with drag-and-drop file uploads
- **Model Training**: Train custom models with your own data
- **Multi-format Support**: Images (JPG, PNG) and audio files (WAV, MP3)

## Technologies Used ğŸ”§

- **Backend**: Python Flask, TensorFlow/Keras, OpenCV
- **Frontend**: HTML5, CSS3, JavaScript
- **Machine Learning**: CNN models for both face and voice recognition
- **Audio Processing**: Librosa for feature extraction
- **Computer Vision**: OpenCV for face detection and processing

## Installation ğŸš€

### Method 1: Automatic Setup
```bash
python setup.py
```

### Method 2: Manual Setup
1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Organize your data:
```
face_data/
â”œâ”€â”€ Person1/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â””â”€â”€ img2.jpg
â””â”€â”€ Person2/
    â”œâ”€â”€ img1.jpg
    â””â”€â”€ img2.jpg

voice_data/
â”œâ”€â”€ Person1/
â”‚   â”œâ”€â”€ sample1.wav
â”‚   â””â”€â”€ sample2.wav
â””â”€â”€ Person2/
    â”œâ”€â”€ sample1.wav
    â””â”€â”€ sample2.wav
```

3. Run the application:
```bash
python app.py
```

4. Open your browser and go to: `http://localhost:5000`

## Usage ğŸ“–

### 1. Training Models
- Click "Train Models" button in the web interface
- The system will automatically process your face_data and voice_data
- Training progress will be displayed with a progress bar
- Models are saved automatically for future use

### 2. Face Recognition
- **Live Camera**: Click "Start Camera" â†’ "Capture Photo"
- **File Upload**: Drag and drop an image or click to browse
- Results show recognized person with confidence score

### 3. Voice Recognition
- **Live Recording**: Click "Start Recording" â†’ speak â†’ "Stop Recording"
- **File Upload**: Drag and drop an audio file or click to browse
- Results show recognized speaker with confidence score

## Data Requirements ğŸ“Š

### Face Data
- **Format**: JPG, PNG images
- **Quantity**: At least 5-10 images per person
- **Quality**: Clear, well-lit faces
- **Size**: Any size (automatically resized to 128x128)

### Voice Data
- **Format**: WAV, MP3 audio files
- **Duration**: 2-5 seconds per sample
- **Quantity**: At least 3-5 samples per person
- **Quality**: Clear speech, minimal background noise

## Model Architecture ğŸ§ 

### Face Recognition CNN
```
Conv2D(32) â†’ MaxPool â†’ Conv2D(64) â†’ MaxPool â†’ Conv2D(128) â†’ MaxPool â†’ Dense(128) â†’ Output
```

### Voice Recognition CNN
```
Input: MFCC features (13Ã—130)
Conv2D(32) â†’ MaxPool â†’ Conv2D(64) â†’ MaxPool â†’ Conv2D(128) â†’ MaxPool â†’ Dense(128) â†’ Output
```

## API Endpoints ğŸ”Œ

- `GET /` - Main web interface
- `POST /train` - Train models with current data
- `POST /recognize_face` - Recognize face from image
- `POST /recognize_voice` - Recognize voice from audio

## Performance Tips ğŸ’¡

1. **Face Recognition**:
   - Use well-lit, clear images
   - Include various angles and expressions
   - Ensure faces are clearly visible

2. **Voice Recognition**:
   - Record in quiet environments
   - Use consistent microphone/recording setup
   - Include various speaking styles

3. **Model Training**:
   - More data generally improves accuracy
   - Balance the number of samples per person
   - Retrain models when adding new people

## Troubleshooting ğŸ”§

### Common Issues

1. **Camera not working**:
   - Check browser permissions
   - Ensure no other applications are using the camera

2. **Microphone not working**:
   - Check browser permissions
   - Verify microphone is properly connected

3. **Poor recognition accuracy**:
   - Add more training samples
   - Ensure good quality data
   - Retrain the models

4. **Installation issues**:
   - Update pip: `python -m pip install --upgrade pip`
   - Use virtual environment
   - Check Python version (3.8+ required)

## File Structure ğŸ“

```
Face Recognition/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ setup.py              # Setup script
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Web interface
â”œâ”€â”€ face_data/           # Face training images
â”œâ”€â”€ voice_data/          # Voice training samples
â”œâ”€â”€ face_model.h5        # Trained face model (generated)
â”œâ”€â”€ voice_model.h5       # Trained voice model (generated)
â”œâ”€â”€ face_encoder.pkl     # Face label encoder (generated)
â””â”€â”€ voice_encoder.pkl    # Voice label encoder (generated)
```

## Security Notes ğŸ”’

- Models and data are stored locally
- No data is transmitted to external servers
- Camera and microphone access requires user permission
- Consider implementing authentication for production use

## Contributing ğŸ¤

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License ğŸ“„

This project is open source and available under the MIT License.

## Credits ğŸ‘

- TensorFlow/Keras for deep learning framework
- OpenCV for computer vision operations
- Librosa for audio processing
- Flask for web framework
